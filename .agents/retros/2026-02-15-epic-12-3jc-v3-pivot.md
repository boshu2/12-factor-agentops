# Retro: Epic 12-3jc — 12-Factor AgentOps v3 Pivot

**Date:** 2026-02-15
**Epic:** 12-3jc (15/15 issues closed)
**Duration:** ~2 hours (research through post-mortem)

## What Went Well

1. **Pre-mortem caught 3 blockers before implementation.** v1 pre-mortem FAILED with inverted adoption model, zero-infrastructure entry missing, and Factor VIII not positioned as hero. Fixing before writing saved full rewrites. Cost: ~5 minutes. Savings: hours.

2. **Parallel factor writing worked at scale.** 12 factors written simultaneously by background agents in Wave 2. All completed successfully. Wave vibe gate caught 5 structural issues (missing sections, wrong heading levels) and they were fixed in one pass.

3. **GOALS.yaml as mechanically-verifiable exit criteria.** 13 shell-script checks eliminated "is this done?" debates. Every check is a grep/wc/find command — zero ambiguity. The `no-stale-framing` check caught 3 files we would have missed manually.

4. **Content budgets prevented bloat.** 400-600 lines per factor target kept content focused. Only Factor VII (4,264 words / 933 lines) exceeded — a minor outlier.

5. **Wave-based execution was efficient.** 4 waves out of 50 max. Wave 1 (archive), Wave 2 (12 factors parallel), Wave 3 (README), Wave 4 (GOALS.yaml verification). Clean progression.

## What Was Hard

1. **Wave 2 agents had inconsistent section naming.** Some used `### The Rule` (h3), others `## The Rule` (h2), others just `## Rule`. The plan specified `## The Rule` but agents interpreted differently. Required post-wave structural fixes.

2. **GOALS.yaml check syntax matters.** The `Rule:` check (with colon) didn't match `## The Rule` (without colon). Caught during Wave 4 verification. Had to fix the check itself, not just the content.

3. **Stale framing references in non-obvious places.** `docs/00-SUMMARY.md`, `CONTRIBUTING.md`, and tutorial link text all contained old framing. The `no-stale-framing` GOALS.yaml check caught these mechanically — manual review would have missed them.

4. **zsh vs bash variable behavior.** Running GOALS.yaml checks with `&&` chaining in zsh produced wrong results for counter variables. All checks needed to run in explicit `bash -c` subshells.

5. **Context compaction during long RPI lifecycle.** The full RPI (research → plan → pre-mortem → crank → vibe → post-mortem) exceeded context limits, requiring session continuation with summary recovery.

## Do Differently Next Time

1. **Include exact markdown templates in worker prompts.** Don't just list section names — provide the exact heading format with level indicators. e.g., `## The Rule` not just "The Rule section".

2. **Test GOALS.yaml checks against sample content before implementation.** Write a test factor stub and run all checks against it. Catches syntax mismatches before workers produce content.

3. **Run stale-framing check incrementally.** Don't wait for Wave 4 — run `no-stale-framing` after each wave to catch drift early.

4. **Always use bash for shell-script checks.** Avoid zsh-specific behavior by wrapping all verification in `bash -c`.

## Patterns to Reuse

1. **PATTERN: Pre-mortem as Plan Gate**
   - Problem: Plans with structural flaws get implemented, requiring full rewrites
   - Solution: Run `/pre-mortem` with council judges before any implementation. FAIL verdict → fix plan → re-run.
   - Evidence: v1 FAIL caught 3 blockers that would have cost hours of rework.

2. **PATTERN: Parallel Agent Writing with Vibe Gate**
   - Problem: N agents writing simultaneously produce inconsistent output
   - Solution: Let agents write in parallel, then run structural vibe gate on all output. Fix inconsistencies in one batch.
   - Evidence: 12 factors written in parallel, 5 structural issues caught and fixed in ~10 minutes.

3. **PATTERN: Mechanically-Verifiable Exit Criteria (GOALS.yaml)**
   - Problem: "Is this done?" debates waste time and introduce subjectivity
   - Solution: Define all exit criteria as shell-script checks. Run them mechanically. 100% pass = done.
   - Evidence: 13 checks, all passing. No subjective judgment needed for completion.

4. **PATTERN: Inverted Adoption Model**
   - Problem: "Read the manifesto first" repels users who want quick value
   - Solution: Lead with 5-minute quickstart that delivers value, then explain principles
   - Evidence: README restructured to quickstart → factors → deep dive. Pre-mortem specifically flagged the original manifesto-first approach.

## Anti-Patterns to Avoid

1. **ANTI-PATTERN: Section Name Without Format Spec**
   - Problem: Telling agents "include a Rule section" without specifying `## The Rule` (h2, with "The")
   - Prevention: Always include exact markdown heading in worker prompts
   - Evidence: 5 of 12 factors had inconsistent heading formats

2. **ANTI-PATTERN: Check-Then-Fix Instead of Prevent**
   - Problem: GOALS.yaml check syntax wasn't validated against actual content format until Wave 4
   - Prevention: Test checks against sample content before implementation starts
   - Evidence: `Rule:` vs `## The Rule` mismatch caught late

3. **ANTI-PATTERN: Assuming Shell Compatibility**
   - Problem: GOALS.yaml checks worked in bash but produced wrong results in zsh
   - Prevention: Always wrap shell checks in explicit `bash -c` invocations
   - Evidence: Counter variable `count=$((count+1))` with `&&` behaved differently in zsh
